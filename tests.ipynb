{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55c27752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:07.29831Z",
     "start_time": "2024-04-30T21:25:05.354584Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:41.955742Z",
     "iopub.status.busy": "2025-04-11T18:30:41.955014Z",
     "iopub.status.idle": "2025-04-11T18:30:51.632223Z",
     "shell.execute_reply": "2025-04-11T18:30:51.631404Z"
    },
    "papermill": {
     "duration": 9.684855,
     "end_time": "2025-04-11T18:30:51.634701",
     "exception": false,
     "start_time": "2025-04-11T18:30:41.949846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from src.dataset.dataset import TrainDataset, TestDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213a77a",
   "metadata": {
    "papermill": {
     "duration": 0.00379,
     "end_time": "2025-04-11T18:30:51.650496",
     "exception": false,
     "start_time": "2025-04-11T18:30:51.646706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare custom dataset loader\n",
    "\n",
    "We have to slightly update the Dataset to provide the relevant data in the appropriate format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201a02b1",
   "metadata": {
    "papermill": {
     "duration": 0.003709,
     "end_time": "2025-04-11T18:30:51.684240",
     "exception": false,
     "start_time": "2025-04-11T18:30:51.680531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load metadata and prepare data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b5fc9db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:34.532017Z",
     "start_time": "2024-04-30T21:25:32.615562Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:51.693628Z",
     "iopub.status.busy": "2025-04-11T18:30:51.693293Z",
     "iopub.status.idle": "2025-04-11T18:30:57.431246Z",
     "shell.execute_reply": "2025-04-11T18:30:57.429814Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.745402,
     "end_time": "2025-04-11T18:30:57.433545",
     "exception": false,
     "start_time": "2025-04-11T18:30:51.688143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 14784\n"
     ]
    }
   ],
   "source": [
    "# Dataset and DataLoader\n",
    "batch_size = 128\n",
    "num_workers = 8\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load Test metadata\n",
    "test_data_path = \"data/SatellitePatches/PA-test/\"\n",
    "test_metadata_path = \"data/GLC25_PA_metadata_test.csv\"\n",
    "test_metadata = pd.read_csv(test_metadata_path)\n",
    "test_dataset = TestDataset(test_data_path, test_metadata, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Load Training metadata\n",
    "train_data_path = \"data/SatellitePatches/PA-train\"\n",
    "train_metadata_path = \"data/GLC25_PA_metadata_train.csv\"\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "train_dataset = TrainDataset(train_data_path, train_metadata, transform=transform, grid_length=0.01)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d28d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 88987\n"
     ]
    }
   ],
   "source": [
    "label_dict = train_dataset.label_dict\n",
    "\n",
    "print(f\"Training dataset size: {len(label_dict)}\")\n",
    "\n",
    "print(label_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e8b59",
   "metadata": {
    "papermill": {
     "duration": 0.004179,
     "end_time": "2025-04-11T18:30:57.441900",
     "exception": false,
     "start_time": "2025-04-11T18:30:57.437721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modify pretrained ResNet-18 model\n",
    "\n",
    "To fully use all the R,G,B and NIR channels, we have to modify the input layer of the standard ResNet-18.\n",
    "That is all :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "877d7197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:31.014067Z",
     "start_time": "2024-04-30T21:25:31.01006Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:57.450727Z",
     "iopub.status.busy": "2025-04-11T18:30:57.450448Z",
     "iopub.status.idle": "2025-04-11T18:30:57.528529Z",
     "shell.execute_reply": "2025-04-11T18:30:57.527509Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.084742,
     "end_time": "2025-04-11T18:30:57.530654",
     "exception": false,
     "start_time": "2025-04-11T18:30:57.445912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "from src.helpers import select_device\n",
    "\n",
    "# Check if cuda is available\n",
    "device = select_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 25\n",
    "positive_weigh_factor = 1.0\n",
    "num_classes = 11255 # Number of all unique classes within the PO and PA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d18e72cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m boxes = train_dataset.label_dict\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m filtered_rows = boxes[\u001b[43mboxes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) > \u001b[32m1\u001b[39m)]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Print the filtered rows\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(filtered_rows)\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "boxes = train_dataset.label_dict\n",
    "\n",
    "filtered_rows = boxes[boxes.apply(lambda x: len(x) > 1)]\n",
    "\n",
    "# Print the filtered rows\n",
    "print(filtered_rows)\n",
    "\n",
    "print(len(filtered_rows)/len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7f756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:57.539829Z",
     "iopub.status.busy": "2025-04-11T18:30:57.539525Z",
     "iopub.status.idle": "2025-04-11T18:30:58.466528Z",
     "shell.execute_reply": "2025-04-11T18:30:58.465645Z"
    },
    "papermill": {
     "duration": 0.933587,
     "end_time": "2025-04-11T18:30:58.468395",
     "exception": false,
     "start_time": "2025-04-11T18:30:57.534808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mResNets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ResNet50\n\u001b[32m      4\u001b[39m model = ResNet50()\n\u001b[32m      5\u001b[39m model.to(device)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "from model.ResNets import ResNet50\n",
    "\n",
    "\n",
    "model = ResNet50()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce6243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50(\n",
      "  (model): ResNet(\n",
      "    (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Linear(in_features=2048, out_features=11255, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7946956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:58.478049Z",
     "iopub.status.busy": "2025-04-11T18:30:58.477780Z",
     "iopub.status.idle": "2025-04-11T18:30:58.482847Z",
     "shell.execute_reply": "2025-04-11T18:30:58.482065Z"
    },
    "papermill": {
     "duration": 0.011755,
     "end_time": "2025-04-11T18:30:58.484569",
     "exception": false,
     "start_time": "2025-04-11T18:30:58.472814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set seed for Python's built-in random number generator\n",
    "    torch.manual_seed(seed)\n",
    "    # Set seed for numpy\n",
    "    np.random.seed(seed)\n",
    "    # Set seed for CUDA if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # Set cuDNN's random number generator seed for deterministic behavior\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(77)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd18b4b",
   "metadata": {
    "papermill": {
     "duration": 0.003826,
     "end_time": "2025-04-11T18:30:58.492394",
     "exception": false,
     "start_time": "2025-04-11T18:30:58.488568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "Nothing special, just a standard Pytorch training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d3632",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-30T21:25:34.536634Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:58.502389Z",
     "iopub.status.busy": "2025-04-11T18:30:58.501748Z",
     "iopub.status.idle": "2025-04-12T04:14:09.901308Z",
     "shell.execute_reply": "2025-04-12T04:14:09.900211Z"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 34991.420477,
     "end_time": "2025-04-12T04:14:09.917095",
     "exception": false,
     "start_time": "2025-04-11T18:30:58.496618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 25 epochs started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=83, pipe_handle=104)\u001b[0m\n",
      "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torchvision/__init__.py\"\u001b[0m, line \u001b[35m10\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1;31mfrom torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\u001b[0m  # usort:skip\n",
      "    \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torchvision/models/__init__.py\"\u001b[0m, line \u001b[35m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from .convnext import *\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torchvision/models/convnext.py\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torchvision/ops/__init__.py\"\u001b[0m, line \u001b[35m23\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torchvision/ops/poolers.py\"\u001b[0m, line \u001b[35m10\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from .roi_align import roi_align\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torchvision/ops/roi_align.py\"\u001b[0m, line \u001b[35m7\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from torch._dynamo.utils import is_compile_supported\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_dynamo/__init__.py\"\u001b[0m, line \u001b[35m53\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1;31mfrom .polyfills import loader as _\u001b[0m  # usort: skip # noqa: F401\n",
      "    \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_dynamo/polyfills/loader.py\"\u001b[0m, line \u001b[35m25\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    POLYFILLED_MODULES: tuple[\"ModuleType\", ...] = \u001b[31mtuple\u001b[0m\u001b[1;31m(\u001b[0m\n",
      "                                                   \u001b[31m~~~~~\u001b[0m\u001b[1;31m^\u001b[0m\n",
      "        \u001b[1;31mimportlib.import_module(f\".{submodule}\", package=polyfills.__name__)\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        \u001b[1;31mfor submodule in POLYFILLED_MODULE_NAMES\u001b[0m\n",
      "        \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    \u001b[1;31m)\u001b[0m\n",
      "    \u001b[1;31m^\u001b[0m\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_dynamo/polyfills/loader.py\"\u001b[0m, line \u001b[35m26\u001b[0m, in \u001b[35m<genexpr>\u001b[0m\n",
      "    \u001b[31mimportlib.import_module\u001b[0m\u001b[1;31m(f\".{submodule}\", package=polyfills.__name__)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py\"\u001b[0m, line \u001b[35m88\u001b[0m, in \u001b[35mimport_module\u001b[0m\n",
      "    return \u001b[31m_bootstrap._gcd_import\u001b[0m\u001b[1;31m(name[level:], package, level)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_dynamo/polyfills/builtins.py\"\u001b[0m, line \u001b[35m30\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    @\u001b[31msubstitute_in_graph\u001b[0m\u001b[1;31m(builtins.all, can_constant_fold_through=True)\u001b[0m\n",
      "     \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_dynamo/decorators.py\"\u001b[0m, line \u001b[35m427\u001b[0m, in \u001b[35mwrapper\u001b[0m\n",
      "    rule_map: dict[Any, type[VariableTracker]] = \u001b[31mget_torch_obj_rule_map\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "                                                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_dynamo/trace_rules.py\"\u001b[0m, line \u001b[35m2870\u001b[0m, in \u001b[35mget_torch_obj_rule_map\u001b[0m\n",
      "    obj = load_object(k)\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_dynamo/trace_rules.py\"\u001b[0m, line \u001b[35m2901\u001b[0m, in \u001b[35mload_object\u001b[0m\n",
      "    val = _load_obj_from_str(x[0])\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_dynamo/trace_rules.py\"\u001b[0m, line \u001b[35m2885\u001b[0m, in \u001b[35m_load_obj_from_str\u001b[0m\n",
      "    return getattr(\u001b[31mimportlib.import_module\u001b[0m\u001b[1;31m(module)\u001b[0m, obj_name)\n",
      "                   \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py\"\u001b[0m, line \u001b[35m88\u001b[0m, in \u001b[35mimport_module\u001b[0m\n",
      "    return \u001b[31m_bootstrap._gcd_import\u001b[0m\u001b[1;31m(name[level:], package, level)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_higher_order_ops/map.py\"\u001b[0m, line \u001b[35m6\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from torch._functorch.aot_autograd import AOTConfig, create_joint\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_functorch/aot_autograd.py\"\u001b[0m, line \u001b[35m135\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from .partitioners import default_partition\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_functorch/partitioners.py\"\u001b[0m, line \u001b[35m37\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from ._activation_checkpointing.graph_info_provider import GraphInfoProvider\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/_functorch/_activation_checkpointing/graph_info_provider.py\"\u001b[0m, line \u001b[35m3\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    import networkx as nx\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/networkx/__init__.py\"\u001b[0m, line \u001b[35m26\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from networkx import classes\n",
      "  File \u001b[35m\"/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/networkx/classes/__init__.py\"\u001b[0m, line \u001b[35m4\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from .multidigraph import MultiDiGraph\n",
      "  File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1360\u001b[0m, in \u001b[35m_find_and_load\u001b[0m\n",
      "  File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1331\u001b[0m, in \u001b[35m_find_and_load_unlocked\u001b[0m\n",
      "  File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m935\u001b[0m, in \u001b[35m_load_unlocked\u001b[0m\n",
      "  File \u001b[35m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[35m1022\u001b[0m, in \u001b[35mexec_module\u001b[0m\n",
      "  File \u001b[35m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[35m1155\u001b[0m, in \u001b[35mget_code\u001b[0m\n",
      "  File \u001b[35m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[35m784\u001b[0m, in \u001b[35m_compile_bytecode\u001b[0m\n",
      "\u001b[1;35mKeyboardInterrupt\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m      4\u001b[39m     model.train()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, targets, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      7\u001b[39m         data = data.to(device)\n\u001b[32m      8\u001b[39m         targets = targets.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:493\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:424\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1171\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1164\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_fork.py:20\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(f\"Training for {num_epochs} epochs started.\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets, _) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        pos_weight = targets*positive_weigh_factor  # All positive weights are equal to 10\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 348 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\"Scheduler:\",scheduler.state_dict())\n",
    "\n",
    "# Save the trained model\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"resnet50-untrained.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c12d7",
   "metadata": {
    "papermill": {
     "duration": 0.013546,
     "end_time": "2025-04-12T04:14:09.944423",
     "exception": false,
     "start_time": "2025-04-12T04:14:09.930877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Loop\n",
    "\n",
    "Again, nothing special, just a standard inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a38793",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T04:14:09.972328Z",
     "iopub.status.busy": "2025-04-12T04:14:09.971988Z",
     "iopub.status.idle": "2025-04-12T04:18:21.383060Z",
     "shell.execute_reply": "2025-04-12T04:18:21.381992Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 251.427356,
     "end_time": "2025-04-12T04:18:21.384873",
     "exception": false,
     "start_time": "2025-04-12T04:14:09.957517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.helpers import test_loop\n",
    "\n",
    "surveys, top_k_indices = test_loop(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67773ed5",
   "metadata": {
    "papermill": {
     "duration": 0.026488,
     "end_time": "2025-04-12T04:18:21.438850",
     "exception": false,
     "start_time": "2025-04-12T04:18:21.412362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save prediction file! 🎉🥳🙌🤗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff556b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:18:21.495048Z",
     "iopub.status.busy": "2025-04-12T04:18:21.494708Z",
     "iopub.status.idle": "2025-04-12T04:18:21.673108Z",
     "shell.execute_reply": "2025-04-12T04:18:21.672421Z"
    },
    "papermill": {
     "duration": 0.209123,
     "end_time": "2025-04-12T04:18:21.675144",
     "exception": false,
     "start_time": "2025-04-12T04:18:21.466021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(str, row)) for row in top_k_indices]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'surveyId': surveys,\n",
    "        'predictions': data_concatenated,\n",
    "    }\n",
    ").to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11565823,
     "sourceId": 91196,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35265.370426,
   "end_time": "2025-04-12T04:18:24.491981",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-11T18:30:39.121555",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

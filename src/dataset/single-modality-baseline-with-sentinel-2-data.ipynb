{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76c598c",
   "metadata": {
    "papermill": {
     "duration": 0.004282,
     "end_time": "2025-04-11T18:30:41.945879",
     "exception": false,
     "start_time": "2025-04-11T18:30:41.941597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Simple baseline with Sentinel-2 data — ResNet-18 + Binary Cross Entropy\n",
    "\n",
    "The occurrence of different types of organisms, whether plants or animals, is generally associated with the characteristics of the environment or ecosystem in which they live. This relationship between the presence of species and their habitat is often interdependent and can be affected by various factors, such as climate, which is another modality we provide.\n",
    "\n",
    "To demonstrate the performance while using just the _image data_, i.e., Sentinel Image Patches, we provide a straightforward baseline that is based on a slighly modified ResNet-18 and Binary Cross Entropy. \n",
    "As described above, the satellite patches provide an image-like modalities that captures habitats and other aspects of the locality.\n",
    "\n",
    "Considering the significant extent for enhancing performance of this baseline, we encourage you to experiment with various techniques, architectures, losses, etc.\n",
    "\n",
    "#### **Have Fun!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c27752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:07.29831Z",
     "start_time": "2024-04-30T21:25:05.354584Z"
    },
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:41.955742Z",
     "iopub.status.busy": "2025-04-11T18:30:41.955014Z",
     "iopub.status.idle": "2025-04-11T18:30:51.632223Z",
     "shell.execute_reply": "2025-04-11T18:30:51.631404Z"
    },
    "papermill": {
     "duration": 9.684855,
     "end_time": "2025-04-11T18:30:51.634701",
     "exception": false,
     "start_time": "2025-04-11T18:30:41.949846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukas/Offline/DHBW/semester2/conda/project/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CosineAnnealingLR\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_recall_fscore_support\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91674b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T13:30:07.054038Z",
     "iopub.status.busy": "2024-05-01T13:30:07.053659Z",
     "iopub.status.idle": "2024-05-01T13:30:07.058148Z",
     "shell.execute_reply": "2024-05-01T13:30:07.057269Z",
     "shell.execute_reply.started": "2024-05-01T13:30:07.054008Z"
    },
    "papermill": {
     "duration": 0.003839,
     "end_time": "2025-04-11T18:30:51.642722",
     "exception": false,
     "start_time": "2025-04-11T18:30:51.638883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data description\n",
    "\n",
    "The Sentinel-2 data was acquired through the Sentinel2 satellite program and pre-processed by [Ecodatacube](https://stac.ecodatacube.eu/) to produce raster files scaled to the entire European continent and projected into a unique CRS. \n",
    "Each TIFF file corresponds to a unique observation location (via \"surveyId\"). To load the patches for a selected observation, take the \"surveyId\" from any occurrence CSV and load it following this rule --> '…/CD/AB/XXXXABCD.jpeg'. For example, the image location for the surveyId 3018575 is \"./75/85/3018575.tiff\". For all \"surveyId\" with less than four digits, you can use a similar rule. For a \"surveyId\" 1 is \"./1/1.tiff\".\n",
    "The data can simply be loaded using the following method:\n",
    "\n",
    "```python\n",
    "def construct_patch_path(output_path, survey_id):\n",
    "    \"\"\"Construct the patch file path based on survey_id as './CD/AB/XXXXABCD.tiff'\"\"\"\n",
    "    path = output_path\n",
    "    for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "        path = os.path.join(path, d)\n",
    "\n",
    "    path = os.path.join(path, f\"{survey_id}.tiff\")\n",
    "\n",
    "    return path\n",
    "```\n",
    "\n",
    "**For more information about data processing, normalization, and visualization, please refer to the following notebook**: [Kaggle Notebook](https://www.kaggle.com/code/picekl/sentinel-2-data-processing-and-normalization).\n",
    "\n",
    "**References:**\n",
    "- *Traceability (lineage): The dataset was produced entirely by mosaicking and seasonally aggregating imagery from the Sentinel-2 Level-2A product (https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi/product-types/level-2a)*\n",
    "- *Ecodatacube.eu: Analysis-ready open environmental data cube for Europe (https://doi.org/10.21203/rs.3.rs-2277090/v3)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213a77a",
   "metadata": {
    "papermill": {
     "duration": 0.00379,
     "end_time": "2025-04-11T18:30:51.650496",
     "exception": false,
     "start_time": "2025-04-11T18:30:51.646706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare custom dataset loader\n",
    "\n",
    "We have to slightly update the Dataset to provide the relevant data in the appropriate format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e2fee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:32.627928Z",
     "start_time": "2024-04-30T21:25:32.612131Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:51.660248Z",
     "iopub.status.busy": "2025-04-11T18:30:51.659488Z",
     "iopub.status.idle": "2025-04-11T18:30:51.674577Z",
     "shell.execute_reply": "2025-04-11T18:30:51.673551Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.022281,
     "end_time": "2025-04-11T18:30:51.676595",
     "exception": false,
     "start_time": "2025-04-11T18:30:51.654314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_patch_path(data_path, survey_id):\n",
    "    \"\"\"Construct the patch file path based on plot_id as './CD/AB/XXXXABCD.jpeg'\"\"\"\n",
    "    path = data_path\n",
    "    for d in (str(survey_id)[-2:], str(survey_id)[-4:-2]):\n",
    "        path = os.path.join(path, d)\n",
    "\n",
    "    path = os.path.join(path, f\"{survey_id}.tiff\")\n",
    "\n",
    "    return path\n",
    "\n",
    "def quantile_normalize(band, low=2, high=98):\n",
    "    sorted_band = np.sort(band.flatten())\n",
    "    quantiles = np.percentile(sorted_band, np.linspace(low, high, len(sorted_band)))\n",
    "    normalized_band = np.interp(band.flatten(), sorted_band, quantiles).reshape(band.shape)\n",
    "    \n",
    "    min_val, max_val = np.min(normalized_band), np.max(normalized_band)\n",
    "    \n",
    "    # Prevent division by zero if min_val == max_val\n",
    "    if max_val == min_val:\n",
    "        return np.zeros_like(normalized_band, dtype=np.float32)  # Return an array of zeros\n",
    "\n",
    "    # Perform normalization (min-max scaling)\n",
    "    return ((normalized_band - min_val) / (max_val - min_val)).astype(np.float32)\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, data_dir, metadata, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.metadata = metadata\n",
    "        self.metadata = self.metadata.dropna(subset=\"speciesId\").reset_index(drop=True)\n",
    "        self.metadata['speciesId'] = self.metadata['speciesId'].astype(int)\n",
    "        self.label_dict = self.metadata.groupby('surveyId')['speciesId'].apply(list).to_dict()\n",
    "        \n",
    "        self.metadata = self.metadata.drop_duplicates(subset=\"surveyId\").reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        species_ids = self.label_dict.get(survey_id, [])  # Get list of species IDs for the survey ID\n",
    "        label = torch.zeros(num_classes)  # Initialize label tensor\n",
    "        for species_id in species_ids:\n",
    "            label_id = species_id\n",
    "            label[label_id] = 1  # Set the corresponding class index to 1 for each species\n",
    "        \n",
    "        # Read TIFF files (multispectral bands)\n",
    "        tiff_path = construct_patch_path(self.data_dir, survey_id)\n",
    "        with rasterio.open(tiff_path) as dataset:\n",
    "            image = dataset.read(out_dtype=np.float32)  # Read all bands\n",
    "            image = np.array([quantile_normalize(band) for band in image])  # Apply quantile normalization\n",
    "\n",
    "        image = np.transpose(image, (1, 2, 0))  # Convert to HWC format\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label, survey_id\n",
    "    \n",
    "class TestDataset(TrainDataset):\n",
    "    def __init__(self, data_dir, metadata, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.metadata = metadata\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        survey_id = self.metadata.surveyId[idx]\n",
    "        \n",
    "        # Read TIFF files (multispectral bands)\n",
    "        tiff_path = construct_patch_path(self.data_dir, survey_id)\n",
    "        with rasterio.open(tiff_path) as dataset:\n",
    "            image = dataset.read(out_dtype=np.float32)  # Read all bands\n",
    "            image = np.array([quantile_normalize(band) for band in image])  # Apply quantile normalization\n",
    "\n",
    "        image = np.transpose(image, (1, 2, 0))  # Convert to HWC format\n",
    "        \n",
    "        image = self.transform(image)\n",
    "        return image, survey_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201a02b1",
   "metadata": {
    "papermill": {
     "duration": 0.003709,
     "end_time": "2025-04-11T18:30:51.684240",
     "exception": false,
     "start_time": "2025-04-11T18:30:51.680531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load metadata and prepare data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fc9db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:34.532017Z",
     "start_time": "2024-04-30T21:25:32.615562Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:51.693628Z",
     "iopub.status.busy": "2025-04-11T18:30:51.693293Z",
     "iopub.status.idle": "2025-04-11T18:30:57.431246Z",
     "shell.execute_reply": "2025-04-11T18:30:57.429814Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.745402,
     "end_time": "2025-04-11T18:30:57.433545",
     "exception": false,
     "start_time": "2025-04-11T18:30:51.688143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load Training metadata\n",
    "train_data_path = \"/data/SatelitePatches/PA-train\"\n",
    "train_metadata_path = \"/data/GLC25_PA_metadata_train.csv\"\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "train_dataset = TrainDataset(train_data_path, train_metadata, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Load Test metadata\n",
    "test_data_path = \"/data/SatelitePatches/PA-test/\"\n",
    "test_metadata_path = \"/data/GLC25_PA_metadata_test.csv\"\n",
    "test_metadata = pd.read_csv(test_metadata_path)\n",
    "test_dataset = TestDataset(test_data_path, test_metadata, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e8b59",
   "metadata": {
    "papermill": {
     "duration": 0.004179,
     "end_time": "2025-04-11T18:30:57.441900",
     "exception": false,
     "start_time": "2025-04-11T18:30:57.437721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modify pretrained ResNet-18 model\n",
    "\n",
    "To fully use all the R,G,B and NIR channels, we have to modify the input layer of the standard ResNet-18.\n",
    "That is all :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d7197",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T21:25:31.014067Z",
     "start_time": "2024-04-30T21:25:31.01006Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:57.450727Z",
     "iopub.status.busy": "2025-04-11T18:30:57.450448Z",
     "iopub.status.idle": "2025-04-11T18:30:57.528529Z",
     "shell.execute_reply": "2025-04-11T18:30:57.527509Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.084742,
     "end_time": "2025-04-11T18:30:57.530654",
     "exception": false,
     "start_time": "2025-04-11T18:30:57.445912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = CUDA\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"DEVICE = CUDA\")\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 25\n",
    "positive_weigh_factor = 1.0\n",
    "num_classes = 11255 # Number of all unique classes within the PO and PA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7f756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:57.539829Z",
     "iopub.status.busy": "2025-04-11T18:30:57.539525Z",
     "iopub.status.idle": "2025-04-11T18:30:58.466528Z",
     "shell.execute_reply": "2025-04-11T18:30:58.465645Z"
    },
    "papermill": {
     "duration": 0.933587,
     "end_time": "2025-04-11T18:30:58.468395",
     "exception": false,
     "start_time": "2025-04-11T18:30:57.534808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 138MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.conv1 = nn.Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2))\n",
    "model.fc = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7946956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:58.478049Z",
     "iopub.status.busy": "2025-04-11T18:30:58.477780Z",
     "iopub.status.idle": "2025-04-11T18:30:58.482847Z",
     "shell.execute_reply": "2025-04-11T18:30:58.482065Z"
    },
    "papermill": {
     "duration": 0.011755,
     "end_time": "2025-04-11T18:30:58.484569",
     "exception": false,
     "start_time": "2025-04-11T18:30:58.472814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set seed for Python's built-in random number generator\n",
    "    torch.manual_seed(seed)\n",
    "    # Set seed for numpy\n",
    "    np.random.seed(seed)\n",
    "    # Set seed for CUDA if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        # Set cuDNN's random number generator seed for deterministic behavior\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    elif torch.mps.is_available():\n",
    "        torch.mps.manual_seed(seed)\n",
    "        torch.backends.mps.deterministic = True\n",
    "        torch.backends.mps.benchmark = False\n",
    "\n",
    "set_seed(77)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd18b4b",
   "metadata": {
    "papermill": {
     "duration": 0.003826,
     "end_time": "2025-04-11T18:30:58.492394",
     "exception": false,
     "start_time": "2025-04-11T18:30:58.488568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop\n",
    "\n",
    "Nothing special, just a standard Pytorch training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d3632",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-30T21:25:34.536634Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-11T18:30:58.502389Z",
     "iopub.status.busy": "2025-04-11T18:30:58.501748Z",
     "iopub.status.idle": "2025-04-12T04:14:09.901308Z",
     "shell.execute_reply": "2025-04-12T04:14:09.900211Z"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 34991.420477,
     "end_time": "2025-04-12T04:14:09.917095",
     "exception": false,
     "start_time": "2025-04-11T18:30:58.496618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 25 epochs started.\n",
      "Epoch 1/25, Batch 0/2781, Loss: 0.7829726338386536\n",
      "Epoch 1/25, Batch 348/2781, Loss: 0.010836335830390453\n",
      "Epoch 1/25, Batch 696/2781, Loss: 0.008275602012872696\n",
      "Epoch 1/25, Batch 1044/2781, Loss: 0.007243425585329533\n",
      "Epoch 1/25, Batch 1392/2781, Loss: 0.0057247094810009\n",
      "Epoch 1/25, Batch 1740/2781, Loss: 0.007086535915732384\n",
      "Epoch 1/25, Batch 2088/2781, Loss: 0.005976676009595394\n",
      "Epoch 1/25, Batch 2436/2781, Loss: 0.006345268804579973\n",
      "Adjusting learning rate of group 0 to 9.9606e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 1, 'verbose': True, '_step_count': 2, '_get_lr_called_within_step': False, '_last_lr': [9.96057350657239e-05]}\n",
      "Epoch 2/25, Batch 0/2781, Loss: 0.008067951537668705\n",
      "Epoch 2/25, Batch 348/2781, Loss: 0.006987317465245724\n",
      "Epoch 2/25, Batch 696/2781, Loss: 0.005684624891728163\n",
      "Epoch 2/25, Batch 1044/2781, Loss: 0.006879405118525028\n",
      "Epoch 2/25, Batch 1392/2781, Loss: 0.00664962874725461\n",
      "Epoch 2/25, Batch 1740/2781, Loss: 0.00700350571423769\n",
      "Epoch 2/25, Batch 2088/2781, Loss: 0.004958063829690218\n",
      "Epoch 2/25, Batch 2436/2781, Loss: 0.0057091983035206795\n",
      "Adjusting learning rate of group 0 to 9.8429e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 2, 'verbose': True, '_step_count': 3, '_get_lr_called_within_step': False, '_last_lr': [9.842915805643155e-05]}\n",
      "Epoch 3/25, Batch 0/2781, Loss: 0.0046182237565517426\n",
      "Epoch 3/25, Batch 348/2781, Loss: 0.005613362416625023\n",
      "Epoch 3/25, Batch 696/2781, Loss: 0.00569118419662118\n",
      "Epoch 3/25, Batch 1044/2781, Loss: 0.006592346355319023\n",
      "Epoch 3/25, Batch 1392/2781, Loss: 0.005177484359592199\n",
      "Epoch 3/25, Batch 1740/2781, Loss: 0.006539784371852875\n",
      "Epoch 3/25, Batch 2088/2781, Loss: 0.005197395104914904\n",
      "Epoch 3/25, Batch 2436/2781, Loss: 0.00543660344555974\n",
      "Adjusting learning rate of group 0 to 9.6489e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 3, 'verbose': True, '_step_count': 4, '_get_lr_called_within_step': False, '_last_lr': [9.648882429441257e-05]}\n",
      "Epoch 4/25, Batch 0/2781, Loss: 0.00458271149545908\n",
      "Epoch 4/25, Batch 348/2781, Loss: 0.0047140964306890965\n",
      "Epoch 4/25, Batch 696/2781, Loss: 0.004945175722241402\n",
      "Epoch 4/25, Batch 1044/2781, Loss: 0.004920635372400284\n",
      "Epoch 4/25, Batch 1392/2781, Loss: 0.005050648003816605\n",
      "Epoch 4/25, Batch 1740/2781, Loss: 0.005885661579668522\n",
      "Epoch 4/25, Batch 2088/2781, Loss: 0.005636304616928101\n",
      "Epoch 4/25, Batch 2436/2781, Loss: 0.00506011676043272\n",
      "Adjusting learning rate of group 0 to 9.3815e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 4, 'verbose': True, '_step_count': 5, '_get_lr_called_within_step': False, '_last_lr': [9.381533400219318e-05]}\n",
      "Epoch 5/25, Batch 0/2781, Loss: 0.004385227803140879\n",
      "Epoch 5/25, Batch 348/2781, Loss: 0.005412438418716192\n",
      "Epoch 5/25, Batch 696/2781, Loss: 0.0050168451853096485\n",
      "Epoch 5/25, Batch 1044/2781, Loss: 0.005449444055557251\n",
      "Epoch 5/25, Batch 1392/2781, Loss: 0.005898645613342524\n",
      "Epoch 5/25, Batch 1740/2781, Loss: 0.004785003140568733\n",
      "Epoch 5/25, Batch 2088/2781, Loss: 0.004899210762232542\n",
      "Epoch 5/25, Batch 2436/2781, Loss: 0.004517571534961462\n",
      "Adjusting learning rate of group 0 to 9.0451e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 5, 'verbose': True, '_step_count': 6, '_get_lr_called_within_step': False, '_last_lr': [9.045084971874738e-05]}\n",
      "Epoch 6/25, Batch 0/2781, Loss: 0.005482915788888931\n",
      "Epoch 6/25, Batch 348/2781, Loss: 0.005197787657380104\n",
      "Epoch 6/25, Batch 696/2781, Loss: 0.004538232926279306\n",
      "Epoch 6/25, Batch 1044/2781, Loss: 0.004160645417869091\n",
      "Epoch 6/25, Batch 1392/2781, Loss: 0.0051621668972074986\n",
      "Epoch 6/25, Batch 1740/2781, Loss: 0.0043713697232306\n",
      "Epoch 6/25, Batch 2088/2781, Loss: 0.004441602621227503\n",
      "Epoch 6/25, Batch 2436/2781, Loss: 0.0050195325165987015\n",
      "Adjusting learning rate of group 0 to 8.6448e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 6, 'verbose': True, '_step_count': 7, '_get_lr_called_within_step': False, '_last_lr': [8.644843137107059e-05]}\n",
      "Epoch 7/25, Batch 0/2781, Loss: 0.004558943212032318\n",
      "Epoch 7/25, Batch 348/2781, Loss: 0.00476564047858119\n",
      "Epoch 7/25, Batch 696/2781, Loss: 0.005121392197906971\n",
      "Epoch 7/25, Batch 1044/2781, Loss: 0.004148590844124556\n",
      "Epoch 7/25, Batch 1392/2781, Loss: 0.0039955023676157\n",
      "Epoch 7/25, Batch 1740/2781, Loss: 0.004540701862424612\n",
      "Epoch 7/25, Batch 2088/2781, Loss: 0.004657820798456669\n",
      "Epoch 7/25, Batch 2436/2781, Loss: 0.0036593794357031584\n",
      "Adjusting learning rate of group 0 to 8.1871e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 7, 'verbose': True, '_step_count': 8, '_get_lr_called_within_step': False, '_last_lr': [8.18711994874345e-05]}\n",
      "Epoch 8/25, Batch 0/2781, Loss: 0.004373222589492798\n",
      "Epoch 8/25, Batch 348/2781, Loss: 0.0038853297010064125\n",
      "Epoch 8/25, Batch 696/2781, Loss: 0.004759941715747118\n",
      "Epoch 8/25, Batch 1044/2781, Loss: 0.004501498769968748\n",
      "Epoch 8/25, Batch 1392/2781, Loss: 0.0041613201610744\n",
      "Epoch 8/25, Batch 1740/2781, Loss: 0.004851760808378458\n",
      "Epoch 8/25, Batch 2088/2781, Loss: 0.004077715799212456\n",
      "Epoch 8/25, Batch 2436/2781, Loss: 0.0039825704880058765\n",
      "Adjusting learning rate of group 0 to 7.6791e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 8, 'verbose': True, '_step_count': 9, '_get_lr_called_within_step': False, '_last_lr': [7.679133974894983e-05]}\n",
      "Epoch 9/25, Batch 0/2781, Loss: 0.004469499923288822\n",
      "Epoch 9/25, Batch 348/2781, Loss: 0.0042649214155972\n",
      "Epoch 9/25, Batch 696/2781, Loss: 0.003954038489609957\n",
      "Epoch 9/25, Batch 1044/2781, Loss: 0.004168843850493431\n",
      "Epoch 9/25, Batch 1392/2781, Loss: 0.004423219244927168\n",
      "Epoch 9/25, Batch 1740/2781, Loss: 0.004178362898528576\n",
      "Epoch 9/25, Batch 2088/2781, Loss: 0.0047271777875721455\n",
      "Epoch 9/25, Batch 2436/2781, Loss: 0.003771240124478936\n",
      "Adjusting learning rate of group 0 to 7.1289e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 9, 'verbose': True, '_step_count': 10, '_get_lr_called_within_step': False, '_last_lr': [7.128896457825363e-05]}\n",
      "Epoch 10/25, Batch 0/2781, Loss: 0.003401720430701971\n",
      "Epoch 10/25, Batch 348/2781, Loss: 0.003660402027890086\n",
      "Epoch 10/25, Batch 696/2781, Loss: 0.0038355858996510506\n",
      "Epoch 10/25, Batch 1044/2781, Loss: 0.003966617397964001\n",
      "Epoch 10/25, Batch 1392/2781, Loss: 0.004001307766884565\n",
      "Epoch 10/25, Batch 1740/2781, Loss: 0.0035723727196455\n",
      "Epoch 10/25, Batch 2088/2781, Loss: 0.003856060793623328\n",
      "Epoch 10/25, Batch 2436/2781, Loss: 0.003987784031778574\n",
      "Adjusting learning rate of group 0 to 6.5451e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 10, 'verbose': True, '_step_count': 11, '_get_lr_called_within_step': False, '_last_lr': [6.545084971874737e-05]}\n",
      "Epoch 11/25, Batch 0/2781, Loss: 0.0033597582951188087\n",
      "Epoch 11/25, Batch 348/2781, Loss: 0.0033950433135032654\n",
      "Epoch 11/25, Batch 696/2781, Loss: 0.0030855347868055105\n",
      "Epoch 11/25, Batch 1044/2781, Loss: 0.00363359902985394\n",
      "Epoch 11/25, Batch 1392/2781, Loss: 0.0034896929282695055\n",
      "Epoch 11/25, Batch 1740/2781, Loss: 0.003925295080989599\n",
      "Epoch 11/25, Batch 2088/2781, Loss: 0.004196907859295607\n",
      "Epoch 11/25, Batch 2436/2781, Loss: 0.003126279218122363\n",
      "Adjusting learning rate of group 0 to 5.9369e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 11, 'verbose': True, '_step_count': 12, '_get_lr_called_within_step': False, '_last_lr': [5.936906572928624e-05]}\n",
      "Epoch 12/25, Batch 0/2781, Loss: 0.0035577022936195135\n",
      "Epoch 12/25, Batch 348/2781, Loss: 0.002763285767287016\n",
      "Epoch 12/25, Batch 696/2781, Loss: 0.003300284966826439\n",
      "Epoch 12/25, Batch 1044/2781, Loss: 0.0033998796716332436\n",
      "Epoch 12/25, Batch 1392/2781, Loss: 0.0035293533001095057\n",
      "Epoch 12/25, Batch 1740/2781, Loss: 0.002922136103734374\n",
      "Epoch 12/25, Batch 2088/2781, Loss: 0.0039064413867890835\n",
      "Epoch 12/25, Batch 2436/2781, Loss: 0.003868265775963664\n",
      "Adjusting learning rate of group 0 to 5.3140e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 12, 'verbose': True, '_step_count': 13, '_get_lr_called_within_step': False, '_last_lr': [5.313952597646568e-05]}\n",
      "Epoch 13/25, Batch 0/2781, Loss: 0.003245551371946931\n",
      "Epoch 13/25, Batch 348/2781, Loss: 0.003516002092510462\n",
      "Epoch 13/25, Batch 696/2781, Loss: 0.0030887546017766\n",
      "Epoch 13/25, Batch 1044/2781, Loss: 0.0035648474004119635\n",
      "Epoch 13/25, Batch 1392/2781, Loss: 0.0033015208318829536\n",
      "Epoch 13/25, Batch 1740/2781, Loss: 0.0034877804573625326\n",
      "Epoch 13/25, Batch 2088/2781, Loss: 0.0032302560284733772\n",
      "Epoch 13/25, Batch 2436/2781, Loss: 0.0038840575143694878\n",
      "Adjusting learning rate of group 0 to 4.6860e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 13, 'verbose': True, '_step_count': 14, '_get_lr_called_within_step': False, '_last_lr': [4.6860474023534335e-05]}\n",
      "Epoch 14/25, Batch 0/2781, Loss: 0.0037074859719723463\n",
      "Epoch 14/25, Batch 348/2781, Loss: 0.003100238973274827\n",
      "Epoch 14/25, Batch 696/2781, Loss: 0.003544642124325037\n",
      "Epoch 14/25, Batch 1044/2781, Loss: 0.00309728248976171\n",
      "Epoch 14/25, Batch 1392/2781, Loss: 0.003371905768290162\n",
      "Epoch 14/25, Batch 1740/2781, Loss: 0.0031191674061119556\n",
      "Epoch 14/25, Batch 2088/2781, Loss: 0.0035033226013183594\n",
      "Epoch 14/25, Batch 2436/2781, Loss: 0.0030708115082234144\n",
      "Adjusting learning rate of group 0 to 4.0631e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 14, 'verbose': True, '_step_count': 15, '_get_lr_called_within_step': False, '_last_lr': [4.0630934270713774e-05]}\n",
      "Epoch 15/25, Batch 0/2781, Loss: 0.0030566805507987738\n",
      "Epoch 15/25, Batch 348/2781, Loss: 0.0032603424042463303\n",
      "Epoch 15/25, Batch 696/2781, Loss: 0.0028813753742724657\n",
      "Epoch 15/25, Batch 1044/2781, Loss: 0.002687947591766715\n",
      "Epoch 15/25, Batch 1392/2781, Loss: 0.0032789784017950296\n",
      "Epoch 15/25, Batch 1740/2781, Loss: 0.003313425462692976\n",
      "Epoch 15/25, Batch 2088/2781, Loss: 0.0032382886856794357\n",
      "Epoch 15/25, Batch 2436/2781, Loss: 0.003282953053712845\n",
      "Adjusting learning rate of group 0 to 3.4549e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 15, 'verbose': True, '_step_count': 16, '_get_lr_called_within_step': False, '_last_lr': [3.454915028125265e-05]}\n",
      "Epoch 16/25, Batch 0/2781, Loss: 0.003359935712069273\n",
      "Epoch 16/25, Batch 348/2781, Loss: 0.00277696386910975\n",
      "Epoch 16/25, Batch 696/2781, Loss: 0.0030852241907268763\n",
      "Epoch 16/25, Batch 1044/2781, Loss: 0.002657495904713869\n",
      "Epoch 16/25, Batch 1392/2781, Loss: 0.002815704559907317\n",
      "Epoch 16/25, Batch 1740/2781, Loss: 0.0036229989491403103\n",
      "Epoch 16/25, Batch 2088/2781, Loss: 0.0031195266637951136\n",
      "Epoch 16/25, Batch 2436/2781, Loss: 0.0036777767818421125\n",
      "Adjusting learning rate of group 0 to 2.8711e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 16, 'verbose': True, '_step_count': 17, '_get_lr_called_within_step': False, '_last_lr': [2.871103542174637e-05]}\n",
      "Epoch 17/25, Batch 0/2781, Loss: 0.0031057109590619802\n",
      "Epoch 17/25, Batch 348/2781, Loss: 0.0030216930899769068\n",
      "Epoch 17/25, Batch 696/2781, Loss: 0.0033555992413312197\n",
      "Epoch 17/25, Batch 1044/2781, Loss: 0.0029425183311104774\n",
      "Epoch 17/25, Batch 1392/2781, Loss: 0.003213426796719432\n",
      "Epoch 17/25, Batch 1740/2781, Loss: 0.0027993337716907263\n",
      "Epoch 17/25, Batch 2088/2781, Loss: 0.0031884044874459505\n",
      "Epoch 17/25, Batch 2436/2781, Loss: 0.0033359054941684008\n",
      "Adjusting learning rate of group 0 to 2.3209e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 17, 'verbose': True, '_step_count': 18, '_get_lr_called_within_step': False, '_last_lr': [2.3208660251050158e-05]}\n",
      "Epoch 18/25, Batch 0/2781, Loss: 0.003081655828282237\n",
      "Epoch 18/25, Batch 348/2781, Loss: 0.0033503989689052105\n",
      "Epoch 18/25, Batch 696/2781, Loss: 0.0030266528483480215\n",
      "Epoch 18/25, Batch 1044/2781, Loss: 0.003294674912467599\n",
      "Epoch 18/25, Batch 1392/2781, Loss: 0.0029073746409267187\n",
      "Epoch 18/25, Batch 1740/2781, Loss: 0.0026320582255721092\n",
      "Epoch 18/25, Batch 2088/2781, Loss: 0.003081731265410781\n",
      "Epoch 18/25, Batch 2436/2781, Loss: 0.00380804855376482\n",
      "Adjusting learning rate of group 0 to 1.8129e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 18, 'verbose': True, '_step_count': 19, '_get_lr_called_within_step': False, '_last_lr': [1.8128800512565513e-05]}\n",
      "Epoch 19/25, Batch 0/2781, Loss: 0.003023986704647541\n",
      "Epoch 19/25, Batch 348/2781, Loss: 0.0025831100065261126\n",
      "Epoch 19/25, Batch 696/2781, Loss: 0.0027004617732018232\n",
      "Epoch 19/25, Batch 1044/2781, Loss: 0.003244770457968116\n",
      "Epoch 19/25, Batch 1392/2781, Loss: 0.0026890335138887167\n",
      "Epoch 19/25, Batch 1740/2781, Loss: 0.0025266092270612717\n",
      "Epoch 19/25, Batch 2088/2781, Loss: 0.0028888636734336615\n",
      "Epoch 19/25, Batch 2436/2781, Loss: 0.00283431145362556\n",
      "Adjusting learning rate of group 0 to 1.3552e-05.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 19, 'verbose': True, '_step_count': 20, '_get_lr_called_within_step': False, '_last_lr': [1.3551568628929434e-05]}\n",
      "Epoch 20/25, Batch 0/2781, Loss: 0.0032171811908483505\n",
      "Epoch 20/25, Batch 348/2781, Loss: 0.0031847478821873665\n",
      "Epoch 20/25, Batch 696/2781, Loss: 0.0032538315281271935\n",
      "Epoch 20/25, Batch 1044/2781, Loss: 0.002570192329585552\n",
      "Epoch 20/25, Batch 1392/2781, Loss: 0.003434455953538418\n",
      "Epoch 20/25, Batch 1740/2781, Loss: 0.002461165888234973\n",
      "Epoch 20/25, Batch 2088/2781, Loss: 0.002813737839460373\n",
      "Epoch 20/25, Batch 2436/2781, Loss: 0.002921744715422392\n",
      "Adjusting learning rate of group 0 to 9.5492e-06.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 20, 'verbose': True, '_step_count': 21, '_get_lr_called_within_step': False, '_last_lr': [9.549150281252635e-06]}\n",
      "Epoch 21/25, Batch 0/2781, Loss: 0.002314717276021838\n",
      "Epoch 21/25, Batch 348/2781, Loss: 0.0024386164732277393\n",
      "Epoch 21/25, Batch 696/2781, Loss: 0.002523368690162897\n",
      "Epoch 21/25, Batch 1044/2781, Loss: 0.002978012664243579\n",
      "Epoch 21/25, Batch 1392/2781, Loss: 0.002734595909714699\n",
      "Epoch 21/25, Batch 1740/2781, Loss: 0.003107222728431225\n",
      "Epoch 21/25, Batch 2088/2781, Loss: 0.003006173763424158\n",
      "Epoch 21/25, Batch 2436/2781, Loss: 0.002375049516558647\n",
      "Adjusting learning rate of group 0 to 6.1847e-06.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 21, 'verbose': True, '_step_count': 22, '_get_lr_called_within_step': False, '_last_lr': [6.184665997806822e-06]}\n",
      "Epoch 22/25, Batch 0/2781, Loss: 0.002743286080658436\n",
      "Epoch 22/25, Batch 348/2781, Loss: 0.002321363892406225\n",
      "Epoch 22/25, Batch 696/2781, Loss: 0.00294059282168746\n",
      "Epoch 22/25, Batch 1044/2781, Loss: 0.00220104050822556\n",
      "Epoch 22/25, Batch 1392/2781, Loss: 0.002725892001762986\n",
      "Epoch 22/25, Batch 1740/2781, Loss: 0.002905399538576603\n",
      "Epoch 22/25, Batch 2088/2781, Loss: 0.0028055417351424694\n",
      "Epoch 22/25, Batch 2436/2781, Loss: 0.002822074806317687\n",
      "Adjusting learning rate of group 0 to 3.5112e-06.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 22, 'verbose': True, '_step_count': 23, '_get_lr_called_within_step': False, '_last_lr': [3.5111757055874332e-06]}\n",
      "Epoch 23/25, Batch 0/2781, Loss: 0.0033210853580385447\n",
      "Epoch 23/25, Batch 348/2781, Loss: 0.0028382192831486464\n",
      "Epoch 23/25, Batch 696/2781, Loss: 0.0025853796396404505\n",
      "Epoch 23/25, Batch 1044/2781, Loss: 0.0028922720812261105\n",
      "Epoch 23/25, Batch 1392/2781, Loss: 0.0029655047692358494\n",
      "Epoch 23/25, Batch 1740/2781, Loss: 0.0022026943042874336\n",
      "Epoch 23/25, Batch 2088/2781, Loss: 0.0027229145634919405\n",
      "Epoch 23/25, Batch 2436/2781, Loss: 0.0024004860315471888\n",
      "Adjusting learning rate of group 0 to 1.5708e-06.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 23, 'verbose': True, '_step_count': 24, '_get_lr_called_within_step': False, '_last_lr': [1.570841943568452e-06]}\n",
      "Epoch 24/25, Batch 0/2781, Loss: 0.002341819228604436\n",
      "Epoch 24/25, Batch 348/2781, Loss: 0.0028767359908670187\n",
      "Epoch 24/25, Batch 696/2781, Loss: 0.002564783440902829\n",
      "Epoch 24/25, Batch 1044/2781, Loss: 0.0031540077179670334\n",
      "Epoch 24/25, Batch 1392/2781, Loss: 0.002864932408556342\n",
      "Epoch 24/25, Batch 1740/2781, Loss: 0.0026282756589353085\n",
      "Epoch 24/25, Batch 2088/2781, Loss: 0.002429352141916752\n",
      "Epoch 24/25, Batch 2436/2781, Loss: 0.0030268719419837\n",
      "Adjusting learning rate of group 0 to 3.9426e-07.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 24, 'verbose': True, '_step_count': 25, '_get_lr_called_within_step': False, '_last_lr': [3.942649342761118e-07]}\n",
      "Epoch 25/25, Batch 0/2781, Loss: 0.0025874674320220947\n",
      "Epoch 25/25, Batch 348/2781, Loss: 0.0026793074794113636\n",
      "Epoch 25/25, Batch 696/2781, Loss: 0.0026987632736563683\n",
      "Epoch 25/25, Batch 1044/2781, Loss: 0.00244996533729136\n",
      "Epoch 25/25, Batch 1392/2781, Loss: 0.002693208632990718\n",
      "Epoch 25/25, Batch 1740/2781, Loss: 0.002351062837988138\n",
      "Epoch 25/25, Batch 2088/2781, Loss: 0.002479055430740118\n",
      "Epoch 25/25, Batch 2436/2781, Loss: 0.002580062486231327\n",
      "Adjusting learning rate of group 0 to 0.0000e+00.\n",
      "Scheduler: {'T_max': 25, 'eta_min': 0, 'base_lrs': [0.0001], 'last_epoch': 25, 'verbose': True, '_step_count': 26, '_get_lr_called_within_step': False, '_last_lr': [0.0]}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training for {num_epochs} epochs started.\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets, _) in enumerate(train_loader):\n",
    "\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        pos_weight = targets*positive_weigh_factor  # All positive weights are equal to 10\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 348 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    print(\"Scheduler:\",scheduler.state_dict())\n",
    "\n",
    "# Save the trained model\n",
    "model.eval()\n",
    "torch.save(model.state_dict(), \"resnet18-with-sentinel2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c12d7",
   "metadata": {
    "papermill": {
     "duration": 0.013546,
     "end_time": "2025-04-12T04:14:09.944423",
     "exception": false,
     "start_time": "2025-04-12T04:14:09.930877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Loop\n",
    "\n",
    "Again, nothing special, just a standard inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a38793",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-12T04:14:09.972328Z",
     "iopub.status.busy": "2025-04-12T04:14:09.971988Z",
     "iopub.status.idle": "2025-04-12T04:18:21.383060Z",
     "shell.execute_reply": "2025-04-12T04:18:21.381992Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 251.427356,
     "end_time": "2025-04-12T04:18:21.384873",
     "exception": false,
     "start_time": "2025-04-12T04:14:09.957517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 462/462 [04:11<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_predictions = []\n",
    "    surveys = []\n",
    "    top_k_indices = None\n",
    "    for data, surveyID in tqdm.tqdm(test_loader, total=len(test_loader)):\n",
    "\n",
    "        data = data.to(device)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        predictions = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "        # Sellect top-25 values as predictions\n",
    "        top_25 = np.argsort(-predictions, axis=1)[:, :25] \n",
    "        if top_k_indices is None:\n",
    "            top_k_indices = top_25\n",
    "        else:\n",
    "            top_k_indices = np.concatenate((top_k_indices, top_25), axis=0)\n",
    "\n",
    "        surveys.extend(surveyID.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67773ed5",
   "metadata": {
    "papermill": {
     "duration": 0.026488,
     "end_time": "2025-04-12T04:18:21.438850",
     "exception": false,
     "start_time": "2025-04-12T04:18:21.412362",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save prediction file! 🎉🥳🙌🤗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff556b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T04:18:21.495048Z",
     "iopub.status.busy": "2025-04-12T04:18:21.494708Z",
     "iopub.status.idle": "2025-04-12T04:18:21.673108Z",
     "shell.execute_reply": "2025-04-12T04:18:21.672421Z"
    },
    "papermill": {
     "duration": 0.209123,
     "end_time": "2025-04-12T04:18:21.675144",
     "exception": false,
     "start_time": "2025-04-12T04:18:21.466021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_concatenated = [' '.join(map(str, row)) for row in top_k_indices]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {'surveyId': surveys,\n",
    "     'predictions': data_concatenated,\n",
    "    }).to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11565823,
     "sourceId": 91196,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35265.370426,
   "end_time": "2025-04-12T04:18:24.491981",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-11T18:30:39.121555",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
